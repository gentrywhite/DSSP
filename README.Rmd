---
output:
  github_document:
    pandoc_args: --webtex
editor_options: 
  markdown: 
    wrap: 72
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# DSSP

<!-- badges: start -->
[![R-CMD-check](https://github.com/gentrywhite/DSSP/workflows/R-CMD-check/badge.svg)](https://github.com/gentrywhite/DSSP/actions)
[![CRAN downloads](https://cranlogs.r-pkg.org/badges/last-month/DSSP)](https://www.r-pkg.org/pkg/DSSP)
[![arXiv](https://img.shields.io/badge/arXiv-1906.05575-00ff00.svg)](https://arxiv.org/abs/1906.05575)
<!-- badges: end -->

The goal of DSSP is to draw samples from the direct sampling spatial
prior model (DSSP) described in White et. al. 2019. The basic model
assumes a Gaussian likelihood and derives a spatial prior based on
thin-plate splines. Functions are included so that the model can be
extended to be used for generalised linear mixed models or Bayesian
Hierarchical Models.

## Installation

You can install the development version from
[GitHub](https://github.com/) with:

```{r, eval=FALSE}
# install.packages("devtools")
devtools::install_github("gentrywhite/DSSP")
```

## Example

Short example using the Meuse dataset from the `{gstat}` package.

```{r example}
data("meuse.all", package = "gstat")
sp::coordinates(meuse.all) <- ~ x + y
```

This model does includes two covariates and their posterior densities are summarised in the `summary()`
```{r}
library(DSSP)
meuse.fit <- DSSP(
  formula = log(zinc) ~ log(lead) + lime, data = meuse.all, N = 10000,
  pars = c(0.001, 0.001), log_prior = function(x) -2 * log(1 + x)
)
summary(meuse.fit)
```

We can inspect several plots for the model using `plot()`.
```{r, fig.height=7, fig.width=7}
plot(meuse.fit)
```

## Introduction

The Direct Sampling Spatial Prior (DSSP) is based on the thin-plate
splines solution to the smoothing problem of minimising the penalised
sum of squares

$$
S_{\eta}(f) = \frac{1}{n}\sum^{n}_{i}W_i(y_i - f(\mathbf{x}_i))^2
+\eta J_m(f)
$$ which can be written as $$
\min_{\mathbf{\nu}}\:(\mathbf{y}-\mathbf{\nu})'\mathbf{W}(\mathbf{y}-\mathbf{\nu})+
\eta\mathbf{\nu}'\mathbf{M}\mathbf{\nu}.
$$ The solution for this problem is $$
\hat{\mathbf{\nu}}=
(\mathbf{W}+\eta\mathbf{M})^{-1}\mathbf{y}.
$$ If we assume that the observed data are from a Gaussian distribution
$$
\mathbf{y}\sim N(\mathbf{\nu},\delta\mathbf{W}^{-1})
$$ and if we specify the prior for $\mathbf{\nu}$ $$
\left[\mathbf{\nu}\mid\eta,\delta\right]\propto\ \frac{\eta}{\delta}^{-{r}/2}
\exp\left(-\frac{\eta}{2\delta}\mathbf{\nu}'\mathbf{M}\mathbf{\nu}\right),
$$ the resulting posterior of $\nu$ is proportional to $$
-\frac{1}{2\delta}\left( (\mathbf{y}-\mathbf{\nu})'\mathbf{W}({\mathbf{y}}-\mathbf{\nu})
-\eta\mathbf{\nu}'\mathbf{M}\mathbf{\nu}\right)
$$ which yields the posterior mean with the same solution as the
penalised least squares.

The complete model is specified with a Gaussian likelihood, the improper
prior for $\nu$, an inverse gaussian prior for $\delta$, and a prior for
$\eta$. With this specification the joint posterior is written $$
\pi\left(\mathbf{\nu},\delta_0,\eta|\mathbf{y}\right)\propto
f(\mathbf{y}|\mathbf{\nu},\delta)\pi\left(\mathbf{\nu}|\eta,\delta\right)\pi\left(\delta\right)
\pi\left(\eta\right).
$$ Given this it is possible to derive the set of posterior
distributions $$\pi\left(\mathbf{\nu}|\delta,\eta,\mathbf{y}\right)\\$$
$$\pi\left(\delta|\eta,\mathbf{y}\right)\\$$
$$\pi\left(\eta|\mathbf{y}\right)$$

which can be sampled directly in sequence to create a draw from the
joint posterior $$
\pi\left(\mathbf{\nu},\delta_0,\eta|\mathbf{y}\right).
$$ This is the heart of what the function `DSSP()` does^[see G. White, D. Sun, P. Speckman (2019) <arXiv:1906.05575> for details].
