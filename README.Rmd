---
output:
  github_document:
    pandoc_args: --webtex
editor_options: 
  markdown: 
    wrap: 72
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# DSSP

<!-- badges: start -->

[![R-CMD-check](https://github.com/gentrywhite/DSSP/workflows/R-CMD-check/badge.svg)](https://github.com/gentrywhite/DSSP/actions)

<!-- badges: end -->

The goal of DSSP is to draw samples from the direct sampling spatial
prior model (DSSP) described in White et. al. 2019. The basic model
assumes a Gaussian likelihood and derives a spatial prior based on
thin-plate splines. Functions are included so that the model can be
extended to be used for generalised linear mixed models or Bayesian
Hierarchical Models.

## Installation

You can install the development version from
[GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("gentrywhite/DSSP")
```

## Example

Short example using the Meuse dataset from the `{gstat}` package.

```{r example}
data("meuse.all", package = "gstat")
meuse.train <- meuse.all[1:155, ]
meuse.valid <- meuse.all[156:164, c("x", "y")]
sp::coordinates(meuse.train) <- ~ x + y
sp::coordinates(meuse.valid) <- ~ x + y
```

This model does not include any covariates.

```{r}
library(DSSP)
meuse.fit <- DSSP(
  formula = log(zinc) ~ 1, data = meuse.train, N = 10000,
  pars = c(0.001, 0.001), log_prior = function(x) -2 * log(1 + x)
)
```

The fitted values are close to the actual values.

```{r}
library(ggplot2)
Yhat <- rowMeans(exp(meuse.fit$y_fitted))
Ytrue <- meuse.all$zinc[1:155]

data.frame(Yhat = Yhat, Ytrue = Ytrue) |>
  ggplot(aes(x = Yhat, y = Ytrue)) +
  geom_point(size = 3) +
  geom_abline(aes(intercept = 0, slope = 1)) +
  labs(x = "Smoothed Values", y = "Observed Values", title = "Smoothed vs. Observed Values") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_bw()
```

## Introduction

The Direct Sampling Spatial Prior (DSSP) is based on the thin-plate
splines solution to the smoothing problem of minimising the penalised
sum of squares

$$
S_{\eta}(f) = \frac{1}{n}\sum^{n}_{i}W_i(y_i - f(\mathbf{x}_i))^2
+\eta J_m(f)
$$ which can be written as $$
\min_{\mathbf{\nu}}\:(\mathbf{y}-\mathbf{\nu})'\mathbf{W}(\mathbf{y}-\mathbf{\nu})+
\eta\mathbf{\nu}'\mathbf{M}\mathbf{\nu}.
$$ The solution for this problem is $$
\hat{\mathbf{\nu}}=
(\mathbf{W}+\eta\mathbf{M})^{-1}\mathbf{y}.
$$ If we assume that the observed data are from a Gaussian distribution
$$
\mathbf{y}\sim N(\mathbf{\nu},\delta\mathbf{W}^{-1})
$$ and if we specify the prior for $\mathbf{\nu}$ $$
\left[\mathbf{\nu}\mid\eta,\delta\right]\propto\ \frac{\eta}{\delta}^{-{r}/2}
\exp\left(-\frac{\eta}{2\delta}\mathbf{\nu}'\mathbf{M}\mathbf{\nu}\right),
$$ the resulting posterior of $\nu$ is proportional to $$
-\frac{1}{2\delta}\left( (\mathbf{y}-\mathbf{\nu})'\mathbf{W}({\mathbf{y}}-\mathbf{\nu})
-\eta\mathbf{\nu}'\mathbf{M}\mathbf{\nu}\right)
$$ which yields the posterior mean with the same solution as the
penalised least squares.

The complete model is specified with a Gaussian likelihood, the improper
prior for $\nu$, an inverse gaussian prior for $\delta$, and a prior for
$\eta$. With this specification the joint posterior is written $$
\pi\left(\mathbf{\nu},\delta_0,\eta|\mathbf{y}\right)\propto
f(\mathbf{y}|\mathbf{\nu},\delta)\pi\left(\mathbf{\nu}|\eta,\delta\right)\pi\left(\delta\right)
\pi\left(\eta\right).
$$ Given this it is possible to derive the set of posterior
distributions $$\pi\left(\mathbf{\nu}|\delta,\eta,\mathbf{y}\right)\\$$
$$\pi\left(\delta|\eta,\mathbf{y}\right)\\$$
$$\pi\left(\eta|\mathbf{y}\right)$$

which can be sampled directly in sequence to create a draw from the
joint posterior $$
\pi\left(\mathbf{\nu},\delta_0,\eta|\mathbf{y}\right).
$$ This is the heart of what the function `DSSP()` does^[see White
et.al. 2018 for details].
